# 手稿
    
    将所有仓库下载并放在同一个目录下，然后手动整理一下文件，将一些非必要文件删除掉，如二进制数据文件，临时文件等。

    创建一个新的 Python 虚拟环境，然后激活并进入该环境

    安装必要的依赖包，如使用 OpenAI 的 Embedding 模型，则安装 `openai` 包。

    ```bash
    pip install openai  # Embedding 模型
    ```

    ```bash
    pip install tiktoken  # Tokenizer
    ```

    ```bash
    pip install rank-bm25   # BM25 模型 - 因为 OpenAI 的 Embedding 模型仅提供稠密向量，无法处理稀疏向量。因此我们需要 BM25 做混合检索
    ```

    ```bash
    pip install faiss-cpu   # Faiss 向量数据库
    ```

    ```bash
    pip install tree_sitter     # 语法树解析
    ```

使用 chunk.py 脚本对代码库进行分块处理，生成 JSONL 格式的文件

```bash
python chunk.py --repo ./your_repo --output chunks.jsonl
```

参数说明
参数	默认值	说明
--repo	. (当前目录)	要处理的代码仓库路径
--output	必需	输出的 JSONL 文件路径
--max-tokens	500	每个文本块的最大 token 数
--overlap	50	相邻文本块的重叠 token 数
--max-file-size	5242880 (5MB)	单个文件的最大字节数
--exclude-dirs	见下方	要排除的目录名列表
--exclude-globs	[]	要排除的路径片段
--no-file-type-limit	False	处理所有可读文本文件